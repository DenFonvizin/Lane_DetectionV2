{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test#3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP/zaIDEtSG47a3ccvGbaaY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"xXa3Zt5zIGBR","executionInfo":{"status":"ok","timestamp":1622311467436,"user_tz":-300,"elapsed":544,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["#import libraries\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","import cv2\n","import glob\n","import os\n","from moviepy.editor import VideoFileClip\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSWue86JIU3y","executionInfo":{"status":"ok","timestamp":1622311468059,"user_tz":-300,"elapsed":15,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}},"outputId":"f2c02104-b641-48dc-aead-aab544e2076e"},"source":["!git clone https://github.com/DenFonvizin/Lane_DetectionV2.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Lane_DetectionV2' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kmWBF4vTISHT","executionInfo":{"status":"ok","timestamp":1622311468060,"user_tz":-300,"elapsed":6,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 1: Camera Calibration ###\n","\n","def distortion_factors():\n","    # Prepare object points\n","    # From the provided calibration images, 9*6 corners are identified \n","    nx = 9\n","    ny = 6\n","    objpoints = []\n","    imgpoints = []\n","    # Object points are real world points, here a 3D coordinates matrix is generated\n","    # z coordinates are 0 and x, y are equidistant as it is known that the chessboard is made of identical squares\n","    objp = np.zeros((6*9,3), np.float32)\n","    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n","  \n","    # Make a list of calibration images\n","    os.listdir(\"Lane_DetectionV2/camera_cal/\")\n","    cal_img_list = os.listdir(\"Lane_DetectionV2/camera_cal/\")  \n","    \n","    # Imagepoints are the coresspondant object points with their coordinates in the distorted image\n","    # They are found in the image using the Open CV 'findChessboardCorners' function\n","    for image_name in cal_img_list:\n","        import_from = 'Lane_DetectionV2/camera_cal/' + image_name\n","        img = cv2.imread(import_from)\n","        # Convert to grayscale\n","        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        # Find the chessboard corners\n","        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n","        # If found, draw corners\n","        if ret == True:\n","            # Draw and display the corners\n","            #cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n","            imgpoints.append(corners)\n","            objpoints.append(objp)\n","    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n","            \n","    return mtx, dist"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZKDFM8OIptB","executionInfo":{"status":"ok","timestamp":1622311470608,"user_tz":-300,"elapsed":2553,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 2: Perspective Transform from Car Camera to Bird's Eye View ###\n","mtx, dist = distortion_factors()\n","\n","def warp(img):\n","    undist = cv2.undistort(img, mtx, dist, None, mtx)\n","    img_size = (img.shape[1], img.shape[0])\n","    offset = 300\n","    \n","    # Source points taken from images with straight lane lines, these are to become parallel after the warp transform\n","    src = np.float32([\n","        (320, 540), # bottom-left corner\n","        (460, 380), # top-left corner\n","        (525, 380), # top-right corner\n","        (730, 540) # bottom-right corner\n","    ])\n","    # Destination points are to be parallel, taken into account the image size\n","    dst = np.float32([\n","        [offset, img_size[1]],             # bottom-left corner\n","        [offset, 0],                       # top-left corner\n","        [img_size[0]-offset, 0],           # top-right corner\n","        [img_size[0]-offset, img_size[1]]  # bottom-right corner\n","    ])\n","    # Calculate the transformation matrix and it's inverse transformation\n","    M = cv2.getPerspectiveTransform(src, dst)\n","    M_inv = cv2.getPerspectiveTransform(dst, src)\n","    warped = cv2.warpPerspective(undist, M, img_size)\n","   \n","    return warped, M_inv"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPOUVdyzJEPR","executionInfo":{"status":"ok","timestamp":1622311470610,"user_tz":-300,"elapsed":24,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 3: Process Binary Thresholded Images ###\n","\n","def binary_thresholded(img):\n","    # Transform image to gray scale\n","    gray_img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Apply sobel (derivative) in x direction, this is usefull to detect lines that tend to be vertical\n","    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0)\n","    abs_sobelx = np.absolute(sobelx)\n","    # Scale result to 0-255\n","    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n","    sx_binary = np.zeros_like(scaled_sobel)\n","    # Keep only derivative values that are in the margin of interest\n","    sx_binary[(scaled_sobel >= 7) & (scaled_sobel <= 255)] = 1\n","\n","    binary = sx_binary\n","    \n","    return binary"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"yDv_tVTnJH7J","executionInfo":{"status":"ok","timestamp":1622311470611,"user_tz":-300,"elapsed":14,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["img = cv2.imread('1.jpg')\n","\n","\n","binary_thresh = binary_thresholded(img)\n","out_img = np.dstack((binary_thresh, binary_thresh, binary_thresh))*255\n","binary_warped, M_inv = warp(binary_thresh)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ifnBWMgJWmA","executionInfo":{"status":"ok","timestamp":1622311470612,"user_tz":-300,"elapsed":14,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 4: Detection of Lane Lines Using Histogram ###\n","\n","def find_lane_pixels_using_histogram(binary_warped):\n","    # Take a histogram of the bottom half of the image\n","    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n","    \n","    # Find the peak of the left and right halves of the histogram\n","    # These will be the starting point for the left and right lines\n","    midpoint = np.int(histogram.shape[0]//2)\n","    leftx_base = np.argmax(histogram[:midpoint])\n","    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n","\n","    # Choose the number of sliding windows\n","    nwindows = 9\n","    # Set the width of the windows +/- margin\n","    margin = 100\n","    # Set minimum number of pixels found to recenter window\n","    minpix = 50\n","\n","    # Set height of windows - based on nwindows above and image shape\n","    window_height = np.int(binary_warped.shape[0]//nwindows)\n","    # Identify the x and y positions of all nonzero pixels in the image\n","    nonzero = binary_warped.nonzero()\n","    nonzeroy = np.array(nonzero[0])\n","    nonzerox = np.array(nonzero[1])\n","    # Current positions to be updated later for each window in nwindows\n","    leftx_current = leftx_base\n","    rightx_current = rightx_base\n","\n","    # Create empty lists to receive left and right lane pixel indices\n","    left_lane_inds = []\n","    right_lane_inds = []\n","\n","    # Step through the windows one by one\n","    for window in range(nwindows):\n","        # Identify window boundaries in x and y (and right and left)\n","        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n","        win_y_high = binary_warped.shape[0] - window*window_height\n","        win_xleft_low = leftx_current - margin\n","        win_xleft_high = leftx_current + margin\n","        win_xright_low = rightx_current - margin\n","        win_xright_high = rightx_current + margin\n","        \n","        # Identify the nonzero pixels in x and y within the window #\n","        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n","        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n","        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n","        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n","        \n","        # Append these indices to the lists\n","        left_lane_inds.append(good_left_inds)\n","        right_lane_inds.append(good_right_inds)\n","        \n","        # If you found > minpix pixels, recenter next window on their mean position\n","        if len(good_left_inds) > minpix:\n","            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n","        if len(good_right_inds) > minpix:        \n","            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n","\n","    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n","    try:\n","        left_lane_inds = np.concatenate(left_lane_inds)\n","        right_lane_inds = np.concatenate(right_lane_inds)\n","    except ValueError:\n","        # Avoids an error if the above is not implemented fully\n","        pass\n","\n","    # Extract left and right line pixel positions\n","    leftx = nonzerox[left_lane_inds]\n","    lefty = nonzeroy[left_lane_inds] \n","    rightx = nonzerox[right_lane_inds]\n","    righty = nonzeroy[right_lane_inds]\n","\n","    return leftx, lefty, rightx, righty\n","\n","\n","def fit_poly(binary_warped,leftx, lefty, rightx, righty):\n","    ### Fit a second order polynomial to each with np.polyfit() ###\n","    left_fit = np.polyfit(lefty, leftx, 2)\n","    right_fit = np.polyfit(righty, rightx, 2)   \n","    \n","    # Generate x and y values for plotting\n","    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n","    try:\n","        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n","        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n","    except TypeError:\n","        # Avoids an error if `left` and `right_fit` are still none or incorrect\n","        print('The function failed to fit a line!')\n","        left_fitx = 1*ploty**2 + 1*ploty\n","        right_fitx = 1*ploty**2 + 1*ploty\n","    \n","    return left_fit, right_fit, left_fitx, right_fitx, ploty\n","\n","def draw_poly_lines(binary_warped, left_fitx, right_fitx, ploty):     \n","    # Create an image to draw on and an image to show the selection window\n","    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n","    window_img = np.zeros_like(out_img)\n","        \n","    margin = 100\n","    # Generate a polygon to illustrate the search window area\n","    # And recast the x and y points into usable format for cv2.fillPoly()\n","    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n","    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n","                              ploty])))])\n","    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n","    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n","    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n","                              ploty])))])\n","    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n","\n","    # Draw the lane onto the warped blank image\n","    cv2.fillPoly(window_img, np.int_([left_line_pts]), (100, 100, 0))\n","    cv2.fillPoly(window_img, np.int_([right_line_pts]), (100, 100, 0))\n","    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n","    \n","    # Plot the polynomial lines onto the image\n","    plt.plot(left_fitx, ploty, color='green')\n","    plt.plot(right_fitx, ploty, color='blue')\n","    ## End visualization steps ##\n","    return result\n","    "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2V8T0JdzJc1A","executionInfo":{"status":"ok","timestamp":1622311470613,"user_tz":-300,"elapsed":13,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 5: Detection of Lane Lines Based on Previous Step ###\n","\n","def find_lane_pixels_using_prev_poly(binary_warped):\n","    global prev_left_fit\n","    global prev_right_fit\n","    # width of the margin around the previous polynomial to search\n","    margin = 100\n","    # Grab activated pixels\n","    nonzero = binary_warped.nonzero()\n","    nonzeroy = np.array(nonzero[0])\n","    nonzerox = np.array(nonzero[1])    \n","    ### Set the area of search based on activated x-values ###\n","    ### within the +/- margin of our polynomial function ###\n","    left_lane_inds = ((nonzerox > (prev_left_fit[0]*(nonzeroy**2) + prev_left_fit[1]*nonzeroy + \n","                    prev_left_fit[2] - margin)) & (nonzerox < (prev_left_fit[0]*(nonzeroy**2) + \n","                    prev_left_fit[1]*nonzeroy + prev_left_fit[2] + margin))).nonzero()[0]\n","    right_lane_inds = ((nonzerox > (prev_right_fit[0]*(nonzeroy**2) + prev_right_fit[1]*nonzeroy + \n","                    prev_right_fit[2] - margin)) & (nonzerox < (prev_right_fit[0]*(nonzeroy**2) + \n","                    prev_right_fit[1]*nonzeroy + prev_right_fit[2] + margin))).nonzero()[0]\n","    # Again, extract left and right line pixel positions\n","    leftx = nonzerox[left_lane_inds]\n","    lefty = nonzeroy[left_lane_inds] \n","    rightx = nonzerox[right_lane_inds]\n","    righty = nonzeroy[right_lane_inds]\n","\n","    return leftx, lefty, rightx, righty\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qspi-kZJgK4","executionInfo":{"status":"ok","timestamp":1622311471233,"user_tz":-300,"elapsed":633,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 6: Calculate Vehicle Position and Curve Radius ###\n","\n","def measure_curvature_meters(binary_warped, left_fitx, right_fitx, ploty):\n","    # Define conversions in x and y from pixels space to meters\n","    ym_per_pix = 14/540 # meters per pixel in y dimension\n","    xm_per_pix = 3.7/525 # meters per pixel in x dimension\n","    \n","    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n","    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n","    # Define y-value where we want radius of curvature\n","    # We'll choose the maximum y-value, corresponding to the bottom of the image\n","    y_eval = np.max(ploty)\n","    \n","    # Calculation of R_curve (radius of curvature)\n","    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n","    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n","    \n","    return left_curverad, right_curverad\n","\n","def measure_position_meters(binary_warped, left_fit, right_fit):\n","    # Define conversion in x from pixels space to meters\n","    xm_per_pix = 3.7/525 # meters per pixel in x dimension\n","    # Choose the y value corresponding to the bottom of the image\n","    y_max = binary_warped.shape[0]\n","    # Calculate left and right line positions at the bottom of the image\n","    left_x_pos = left_fit[0]*y_max**2 + left_fit[1]*y_max + left_fit[2]\n","    right_x_pos = right_fit[0]*y_max**2 + right_fit[1]*y_max + right_fit[2] \n","    # Calculate the x position of the center of the lane \n","    center_lanes_x_pos = (left_x_pos + right_x_pos)//2\n","    # Calculate the deviation between the center of the lane and the center of the picture\n","    # The car is assumed to be placed in the center of the picture\n","    # If the deviation is negative, the car is on the felt hand side of the center of the lane\n","    veh_pos = ((binary_warped.shape[1]//2) - center_lanes_x_pos) * xm_per_pix \n","    return veh_pos\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"P1Xau9MkJjOA","executionInfo":{"status":"ok","timestamp":1622311471241,"user_tz":-300,"elapsed":26,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["### STEP 7: Project Lane Delimitations Back on Image Plane and Add Text for Lane Info ###\n","\n","def project_lane_info(img, binary_warped, ploty, left_fitx, right_fitx, M_inv, left_curverad, right_curverad, veh_pos):\n","    # Create an image to draw the lines on\n","    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n","    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n","    \n","    # Recast the x and y points into usable format for cv2.fillPoly()\n","    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n","    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n","    pts = np.hstack((pts_left, pts_right))\n","    \n","    # Draw the lane onto the warped blank image\n","    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n","    \n","    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n","    newwarp = cv2.warpPerspective(color_warp, M_inv, (img.shape[1], img.shape[0]))\n","    \n","    # Combine the result with the original image\n","    out_img = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n","    \n","    cv2.putText(out_img,'Radius of Curvature: '+str((left_curverad+right_curverad)/2)[:7] + \" m\",(20,40), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,0),2,cv2.LINE_AA)\n","    cv2.putText(out_img,'Vehicle offset from lane center: '+str(veh_pos)[:7] + \" m\",(20,70), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(0,0,0),2,cv2.LINE_AA)\n","    \n","    return out_img\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPedkJd8Jmnx","executionInfo":{"status":"ok","timestamp":1622311471242,"user_tz":-300,"elapsed":27,"user":{"displayName":"Denis Lim","photoUrl":"","userId":"05724707113155420709"}}},"source":["global left_fit_hist \n","left_fit_hist = np.array([])\n","#print(len(left_fit_hist))\n","\n","global right_fit_hist \n","right_fit_hist = np.array([])\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdJYGFupJq6g"},"source":["### STEP 8: Lane Finding Pipeline on Video ###\n","\n","def lane_finding_pipeline(img):\n","    global left_fit_hist \n","    global right_fit_hist\n","    global prev_left_fit\n","    global prev_right_fit\n","    binary_thresh = binary_thresholded(img)\n","    binary_warped, M_inv = warp(binary_thresh)\n","    #out_img = np.dstack((binary_thresh, binary_thresh, binary_thresh))*255\n","    if (len(left_fit_hist) == 0):\n","        leftx, lefty, rightx, righty = find_lane_pixels_using_histogram(binary_warped)\n","        left_fit, right_fit, left_fitx, right_fitx, ploty = fit_poly(binary_warped,leftx, lefty, rightx, righty)\n","        # Store fit in history\n","        left_fit_hist = np.array(left_fit)\n","        new_left_fit = np.array(left_fit)\n","        left_fit_hist = np.vstack([left_fit_hist, new_left_fit])\n","        right_fit_hist = np.array(right_fit)\n","        new_right_fit = np.array(right_fit)\n","        right_fit_hist = np.vstack([right_fit_hist, new_right_fit])\n","    else:\n","        prev_left_fit = [np.mean(left_fit_hist[:,0]), np.mean(left_fit_hist[:,1]), np.mean(left_fit_hist[:,2])]\n","        prev_right_fit = [np.mean(right_fit_hist[:,0]), np.mean(right_fit_hist[:,1]), np.mean(right_fit_hist[:,2])]\n","        leftx, lefty, rightx, righty = find_lane_pixels_using_prev_poly(binary_warped)\n","        if (len(lefty) == 0 or len(righty) == 0):\n","            leftx, lefty, rightx, righty = find_lane_pixels_using_histogram(binary_warped)\n","        left_fit, right_fit, left_fitx, right_fitx, ploty = fit_poly(binary_warped,leftx, lefty, rightx, righty)\n","        \n","        # Add new values to history\n","        new_left_fit = np.array(left_fit)\n","        left_fit_hist = np.vstack([left_fit_hist, new_left_fit])\n","        new_right_fit = np.array(right_fit)\n","        right_fit_hist = np.vstack([right_fit_hist, new_right_fit])\n","        \n","        # Remove old values from history\n","        if (len(left_fit_hist) > 20):\n","            left_fit_hist = np.delete(left_fit_hist, 0,0)\n","            right_fit_hist = np.delete(right_fit_hist, 0,0)\n","                                       \n","    left_curverad, right_curverad =  measure_curvature_meters(binary_warped, left_fitx, right_fitx, ploty)\n","                                     #measure_curvature_meters(binary_warped, left_fitx, right_fitx, ploty)\n","    veh_pos = measure_position_meters(binary_warped, left_fit, right_fit) \n","    out_img = project_lane_info(img, binary_warped, ploty, left_fitx, right_fitx, M_inv, left_curverad, right_curverad, veh_pos)\n","    return out_img\n","\n","video_output = 'project_video_output.mp4'\n","clip1 = VideoFileClip(\"lane_detection.mp4\")\n","output_clip = clip1.fl_image(lane_finding_pipeline)\n","%time output_clip.write_videofile(video_output, audio=False)"],"execution_count":null,"outputs":[]}]}